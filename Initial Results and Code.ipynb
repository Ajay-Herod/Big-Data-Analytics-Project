{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.4.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (46.1.3.post20200325)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.16.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydotplus in /opt/conda/lib/python3.7/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from pydotplus) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (0.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Dropout, Input, LSTM, concatenate\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate Exponential Moving Average using simple moving average \n",
    "def ema(values, i):\n",
    "    #Simple moving average\n",
    "    sma = np.mean(values[:, 3])\n",
    "    ema_values = [sma]\n",
    "    k = 2 / (1 + i)\n",
    "    for i in range(len(his) - i, len(his)):\n",
    "        close = his[i][3]\n",
    "        ema_values.append(close * k + ema_values[-1] * (1 - k))\n",
    "    return ema_values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history_points represents the set number of days that affect the next\n",
    "history_points = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import .csv data and remove the Date attribute \n",
    "data = pd.read_csv('SPY.csv')\n",
    "data = data.drop('Date', axis=1)\n",
    "data = data.drop('Adj Close', axis=1)\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data to a MinMaxScaler\n",
    "data_normaliser = preprocessing.MinMaxScaler()\n",
    "data_normalised = data_normaliser.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7075, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data_normalised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using history_points, open, close, high, low, volume, data, points create OpenHighLowChart and next day open values\n",
    "ohlcv_histories_normalised = np.array([data_normalised[i:i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "next_day_open_values_normalised = np.array([data_normalised[:, 0][i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_day_open_values = np.array([data[:, 0][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize the data to a MinMaxScaler\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create technical indicators using simple and exponential moving average\n",
    "technical_indicators = []\n",
    "for his in ohlcv_histories_normalised:\n",
    "    #Simple moving average of the closing price\n",
    "    sma = np.mean(his[:, 3])\n",
    "    macd = ema(his, 12) - ema(his, 26)\n",
    "    #Add the simple and exponential moving average to the technical indicator \n",
    "    technical_indicators.append(np.array([sma,macd,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_indicators = np.array(technical_indicators)\n",
    "\n",
    "tech_ind_scaler = preprocessing.MinMaxScaler()\n",
    "technical_indicators_normalised = tech_ind_scaler.fit_transform(technical_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0] == technical_indicators_normalised.shape[0], \"data shapes are inconsistent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation\n",
    "#Split the data into Training and Testing 9-1 ratio\n",
    "test_split = 0.9\n",
    "#Split number (6322)\n",
    "n = int(ohlcv_histories_normalised.shape[0] * test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7025, 50, 5)\n",
      "(7025, 2)\n"
     ]
    }
   ],
   "source": [
    "print(ohlcv_histories_normalised.shape)\n",
    "print(technical_indicators_normalised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_train = ohlcv_histories_normalised[:n]\n",
    "tech_ind_train = technical_indicators_normalised[:n]\n",
    "y_train = next_day_open_values_normalised[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_test = ohlcv_histories_normalised[n:]\n",
    "tech_ind_test = technical_indicators_normalised[n:]\n",
    "y_test = next_day_open_values_normalised[n:]\n",
    "\n",
    "unscaled_y_test = next_day_open_values[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6322, 50, 5)\n",
      "(703, 50, 5)\n"
     ]
    }
   ],
   "source": [
    "print(ohlcv_train.shape)\n",
    "print(ohlcv_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create LSTM model\n",
    "#Define two sets of inputs\n",
    "lstm_input = Input(shape=(history_points, 5), name='lstm_input')\n",
    "dense_input = Input(shape=(technical_indicators_normalised.shape[1],), name='tech_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First branch operates on the first input\n",
    "x = LSTM(history_points, name='lstm_0')(lstm_input)\n",
    "x = Dropout(0.2, name='lstm_dropout_0')(x)\n",
    "lstm_branch = Model(inputs=lstm_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second branch opreates on the second input\n",
    "y = Dense(20, name='tech_dense_0')(dense_input)\n",
    "y = Activation(\"relu\", name='tech_relu_0')(y)\n",
    "y = Dropout(0.2, name='tech_dropout_0')(y)\n",
    "technical_indicators_branch = Model(inputs=dense_input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the output of the two branches\n",
    "combined = concatenate([lstm_branch.output, technical_indicators_branch.output], name='concatenate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Dense(64, activation=\"sigmoid\", name='dense_pooling')(combined)\n",
    "z = Dense(1, activation=\"linear\", name='dense_out')(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model will accept the inputs of the two branches and then output a single value\n",
    "model = Model(inputs=[lstm_branch.input, technical_indicators_branch.input], outputs=z)\n",
    "adam = optimizers.Adam(lr=0.0005)\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "#Print model diagram\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "178/178 [==============================] - 8s 37ms/step - loss: 0.1816 - val_loss: 0.0053\n",
      "Epoch 2/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 8.2286e-04 - val_loss: 1.9965e-04\n",
      "Epoch 4/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 6.8733e-04 - val_loss: 1.6722e-04\n",
      "Epoch 5/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 5.9437e-04 - val_loss: 1.6238e-04\n",
      "Epoch 6/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 5.1363e-04 - val_loss: 5.6247e-04\n",
      "Epoch 7/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 4.3446e-04 - val_loss: 2.8220e-04\n",
      "Epoch 8/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 3.9332e-04 - val_loss: 2.0411e-04\n",
      "Epoch 9/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 3.4700e-04 - val_loss: 8.1840e-05\n",
      "Epoch 10/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 3.1097e-04 - val_loss: 1.0283e-04\n",
      "Epoch 11/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 2.6432e-04 - val_loss: 3.3485e-04\n",
      "Epoch 12/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 2.3694e-04 - val_loss: 4.5100e-04\n",
      "Epoch 13/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 2.1160e-04 - val_loss: 2.9730e-04\n",
      "Epoch 14/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 1.9145e-04 - val_loss: 1.2025e-04\n",
      "Epoch 15/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 1.6249e-04 - val_loss: 7.9187e-05\n",
      "Epoch 16/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 1.5389e-04 - val_loss: 1.5905e-04\n",
      "Epoch 17/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.4801e-04 - val_loss: 6.7272e-05\n",
      "Epoch 18/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.3777e-04 - val_loss: 2.1031e-04\n",
      "Epoch 19/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.3018e-04 - val_loss: 1.9101e-04\n",
      "Epoch 20/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.3026e-04 - val_loss: 5.6308e-05\n",
      "Epoch 21/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.3083e-04 - val_loss: 1.0275e-04\n",
      "Epoch 22/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.1945e-04 - val_loss: 7.3819e-05\n",
      "Epoch 23/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.1876e-04 - val_loss: 5.3316e-05\n",
      "Epoch 24/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.1321e-04 - val_loss: 7.2847e-05\n",
      "Epoch 25/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 1.1379e-04 - val_loss: 1.9193e-04\n",
      "Epoch 26/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 1.0913e-04 - val_loss: 5.8016e-05\n",
      "Epoch 27/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.1329e-04 - val_loss: 2.9341e-04\n",
      "Epoch 28/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 1.1809e-04 - val_loss: 9.9973e-05\n",
      "Epoch 29/50\n",
      "178/178 [==============================] - 6s 33ms/step - loss: 1.1838e-04 - val_loss: 9.6906e-05\n",
      "Epoch 30/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.1411e-04 - val_loss: 5.1586e-05\n",
      "Epoch 31/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.1226e-04 - val_loss: 4.6670e-05\n",
      "Epoch 32/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.0264e-04 - val_loss: 6.3160e-05\n",
      "Epoch 33/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.0502e-04 - val_loss: 7.6875e-05\n",
      "Epoch 34/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.1307e-04 - val_loss: 9.7018e-05\n",
      "Epoch 35/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.0657e-04 - val_loss: 1.3218e-04\n",
      "Epoch 36/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.0168e-04 - val_loss: 2.5959e-04\n",
      "Epoch 37/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.0760e-04 - val_loss: 9.0648e-05\n",
      "Epoch 38/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.0874e-04 - val_loss: 4.8204e-05\n",
      "Epoch 39/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 9.8711e-05 - val_loss: 3.6766e-04\n",
      "Epoch 40/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.1701e-04 - val_loss: 4.3219e-05\n",
      "Epoch 41/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.1273e-04 - val_loss: 1.7114e-04\n",
      "Epoch 42/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.0346e-04 - val_loss: 1.0875e-04\n",
      "Epoch 43/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 9.1268e-05 - val_loss: 3.4208e-05\n",
      "Epoch 44/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 1.1551e-04 - val_loss: 9.1323e-05\n",
      "Epoch 45/50\n",
      "178/178 [==============================] - 5s 31ms/step - loss: 1.0399e-04 - val_loss: 3.2151e-04\n",
      "Epoch 46/50\n",
      "178/178 [==============================] - 6s 31ms/step - loss: 1.0522e-04 - val_loss: 8.4018e-05\n",
      "Epoch 47/50\n",
      "178/178 [==============================] - 6s 32ms/step - loss: 9.5427e-05 - val_loss: 1.2586e-04\n",
      "Epoch 48/50\n",
      " 31/178 [====>.........................] - ETA: 4s - loss: 1.2207e-04"
     ]
    }
   ],
   "source": [
    "#Train Model model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 100, batch_size = 64, verbose = 1)\n",
    "model.fit(x=[ohlcv_train, tech_ind_train], y=y_train, validation_data=([ohlcv_test, tech_ind_test],y_test), batch_size=32, epochs=history_points, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "evaluation = model.evaluate([ohlcv_test, tech_ind_test], y_test)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ohlcv_test.shape)\n",
    "print(tech_ind_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and check model performance \n",
    "y_test_predicted = model.predict([ohlcv_test, tech_ind_test])\n",
    "y_predicted = model.predict([ohlcv_histories_normalised, technical_indicators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denomaization or scaler inverse\n",
    "y_test_predicted = y_normaliser.inverse_transform(y_test_predicted)\n",
    "y_predicted = y_normaliser.inverse_transform(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unscaled_y_test.shape == y_test_predicted.shape, \"data shapes are inconsistent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Root Mean Square Error performance \n",
    "rmse = np.mean(np.square(unscaled_y_test - y_test_predicted))\n",
    "scaled_mse = rmse / (np.max(unscaled_y_test) - np.min(unscaled_y_test)) * 100\n",
    "print(scaled_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plot\n",
    "plt.gcf().set_size_inches(18, 9, forward=True)\n",
    "real = plt.plot(unscaled_y_test[0:-1], label='real')\n",
    "#Shift test predictions for plotting\n",
    "pred = plt.plot(y_test_predicted[0:-1], label='predicted')\n",
    "#Plot baseline and prediction\n",
    "plt.legend(['Real', 'Predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model for trade program\n",
    "model.save(f'time_series_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
